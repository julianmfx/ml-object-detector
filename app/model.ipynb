{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from config.load_config import load_config\n",
    "import requests\n",
    "from IPython.display import Image, display\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Create enviroment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "cfg = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PEXELS_API_KEY = os.getenv(\"PEXELS_API_KEY\")\n",
    "if not PEXELS_API_KEY:\n",
    "    raise ValueError(\"PEXELS_API_KEY is not set in the environment variables.\")\n",
    "else:\n",
    "    print(\"PEXELS_API_KEY is set.\")\n",
    "BASE_DIR = Path(cfg[\"base_dir\"]).resolve()\n",
    "print(BASE_DIR)\n",
    "INPUT_DIR = Path(BASE_DIR / cfg[\"input_dir\"]).resolve()\n",
    "print(INPUT_DIR)\n",
    "OUTPUT_DIR = Path(BASE_DIR / cfg[\"output_dir\"]).resolve()\n",
    "print(OUTPUT_DIR)\n",
    "MODEL_DIR = Path(BASE_DIR / cfg[\"model_dir\"]).resolve()\n",
    "print(MODEL_DIR)\n",
    "LOGS_DIR = Path(BASE_DIR / cfg[\"logs_dir\"]).resolve()\n",
    "print(LOGS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOGS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FILE = LOGS_DIR / f\"app_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.FileHandler(LOG_FILE, mode=\"a\"), logging.StreamHandler()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Download test images through API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch images from Pexels API\n",
    "headers = {\"Authorization\": PEXELS_API_KEY}\n",
    "params = {\"query\": \"picnic\", \"per_page\": 5}\n",
    "response = requests.get(\n",
    "    \"https://api.pexels.com/v1/search\", headers=headers, params=params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for photo in response.json()[\"photos\"]:\n",
    "    url = photo[\"src\"][\"original\"]\n",
    "    filename = url.split(\"/\")[-1].split(\"?\")[0]\n",
    "    path = INPUT_DIR / filename\n",
    "    img = requests.get(url)\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(img.content)\n",
    "    print(f\"Downloaded {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View test images\n",
    "for image in INPUT_DIR.iterdir():\n",
    "    if image.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        print(f\"Image: {image.name}\")\n",
    "        display(Image(filename=image, width=300, height=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = MODEL_DIR / cfg[\"model_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(model_path)\n",
    "logging.info(f\"Model loaded from: {model_path}\\nModel info:{model.info()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(\n",
    "    source=INPUT_DIR,\n",
    "    save=True,\n",
    "    save_txt=True,\n",
    "    save_conf=True,\n",
    "    project=OUTPUT_DIR,\n",
    "    name=\"predictions\",\n",
    "    #conf=cfg[\"confidence_threshold\"],\n",
    "    conf=0.2,\n",
    "    iou=0.45,\n",
    "    max_det=15,\n",
    "    exist_ok=True,\n",
    ")\n",
    "PREDICTIONS_DIR = OUTPUT_DIR / \"predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View test images\n",
    "for image in PREDICTIONS_DIR.iterdir():\n",
    "    if image.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        print(f\"Image: {image.name}\")\n",
    "        display(Image(filename=image, width=800, height=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Results\n",
    "* We can see the model is good at detecting persons\n",
    "* Other objects are missclassified or the model isn't so secure about it\n",
    "* For example, ChatGPT mentioned that YOLOv8 does not have the class \"basket\" so identifies it as a vase\n",
    "\n",
    "# Actions to improve model\n",
    "* Inspect training labels\n",
    "* Check class definitions\n",
    "* Add diferent images and use augmentation to improve dataset quality\n",
    "* Fine-Tune the model\n",
    "* Evaluate class-level performance (mAP)\n",
    "* Use custom class filtering (can be pre or post prediction)\n",
    "\n",
    "# Next steps\n",
    "* At this stage, the primary goal of the project is to deploy the model using Docker rather than enchancing its prediction accuracy. Accordingly, we will advance from the testing phase tot he deployment process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
